{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、数据类型\n",
    "\n",
    "## 1.1 Constant\n",
    "\n",
    "Tensorflow的Constant可以和python数组一样切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor([[4. 5. 6.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[1. 2. 3.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([2. 5.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "print(t)\n",
    "print(t[1:])\n",
    "print(t[:1])\n",
    "print(t[...,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常量可以很方便的与numpy的数组转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float64)\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]]\n"
     ]
    }
   ],
   "source": [
    "#将constant转换为numpy数组\n",
    "print(t.numpy())\n",
    "\n",
    "#将numpy转换为constant\n",
    "n = np.array([[1., 2., 3.],[4., 5., 6.]])\n",
    "print(tf.constant(n))\n",
    "\n",
    "#部分numpy的操作可以直接作用于constant。其实就是先将constant转换为了numpy数组后再执行，所以结果也是一个numpy数组\n",
    "print(np.square(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用constant表示string："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'cafe', shape=(), dtype=string)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([ 99  97 102 101], shape=(4,), dtype=int32)\n",
      "tf.Tensor([4 6 2], shape=(3,), dtype=int32)\n",
      "<tf.RaggedTensor [[99, 97, 102, 101], [99, 111, 102, 102, 101, 101], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant(\"cafe\")\n",
    "print(t)\n",
    "print(tf.strings.length(t))\n",
    "print(tf.strings.length(t, unit=\"UTF8_CHAR\"))\n",
    "print(tf.strings.unicode_decode(t, \"UTF8\"))\n",
    "\n",
    "# string array\n",
    "t = tf.constant([\"cafe\", \"coffee\", \"咖啡\"])\n",
    "print(tf.strings.length(t, unit=\"UTF8_CHAR\"))\n",
    "r = tf.strings.unicode_decode(t, \"UTF8\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 regged\n",
    "regged用于表示数组内每个维度可以有不同的长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12], [21, 22, 23], [], [41]]>\n",
      "tf.Tensor([21 22 23], shape=(3,), dtype=int32)\n",
      "<tf.RaggedTensor [[21, 22, 23]]>\n"
     ]
    }
   ],
   "source": [
    "r = tf.ragged.constant([[11, 12], [21, 22, 23], [], [41]])\n",
    "# index op\n",
    "print(r)\n",
    "print(r[1])\n",
    "print(r[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12], [21, 22, 23], [], [41], [51, 52], [], [71]]>\n"
     ]
    }
   ],
   "source": [
    "# ops on ragged tensor\n",
    "r2 = tf.ragged.constant([[51, 52], [], [71]])\n",
    "print(tf.concat([r, r2], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12, 13, 14], [21, 22, 23, 15], [], [41, 42, 43]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[13, 14], [15], [], [42, 43]])\n",
    "print(tf.concat([r, r3], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11 12  0]\n",
      " [21 22 23]\n",
      " [ 0  0  0]\n",
      " [41  0  0]], shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r.to_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 sparse tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [0. 0. 0. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# sparse tensor\n",
    "s = tf.SparseTensor(indices = [[0, 1], [1, 0], [2, 3]],\n",
    "                    values = [1., 2., 3.],\n",
    "                    dense_shape = [3, 4])\n",
    "print(s)\n",
    "print(tf.sparse.to_dense(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse tensor的常用操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([2. 4. 6.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "unsupported operand type(s) for +: 'SparseTensor' and 'int'\n",
      "tf.Tensor(\n",
      "[[ 30.  40.]\n",
      " [ 20.  40.]\n",
      " [210. 240.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ops on sparse tensors\n",
    "\n",
    "s2 = s * 2.0\n",
    "print(s2)\n",
    "\n",
    "try:\n",
    "    s3 = s + 1\n",
    "except TypeError as ex:\n",
    "    print(ex)\n",
    "\n",
    "s4 = tf.constant([[10., 20.],\n",
    "                  [30., 40.],\n",
    "                  [50., 60.],\n",
    "                  [70., 80.]])\n",
    "print(tf.sparse.sparse_dense_matmul(s, s4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse tensor的indeice参数需要按顺序，否则就会报错。可以使用reorder()重新排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "tf.Tensor(\n",
      "[[0. 2. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# sparse tensor\n",
    "s5 = tf.SparseTensor(indices = [[0, 2], [0, 1], [2, 3]],\n",
    "                    values = [1., 2., 3.],\n",
    "                    dense_shape = [3, 4])\n",
    "print(s5)\n",
    "s6 = tf.sparse.reorder(s5)\n",
    "print(tf.sparse.to_dense(s6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 变量\n",
    "变量中的数字可以被重新赋值，比如常用于模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[1., 2., 3.],\n",
      "       [4., 5., 6.]], dtype=float32)>\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(v)\n",
    "print(v.value())\n",
    "print(v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.  6.]\n",
      " [ 8. 10. 12.]]\n",
      "[[ 2. 42.  6.]\n",
      " [ 8. 10. 12.]]\n",
      "[[ 2. 42.  6.]\n",
      " [ 7.  8.  9.]]\n"
     ]
    }
   ],
   "source": [
    "# assign value\n",
    "v.assign(2*v)\n",
    "print(v.numpy())\n",
    "v[0, 1].assign(42)\n",
    "print(v.numpy())\n",
    "v[1].assign([7., 8., 9.])\n",
    "print(v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5、tf_function与auto_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tf_function与auto_graph，可以将普通python代码转成tensorflow代码，提高运行效率。\n",
    "\n",
    "方式一：使用转化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aba99cee84c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_elu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_elu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# tf.function and auto-graph.\n",
    "def scaled_elu(z, scale=1.0, alpha=1.0):\n",
    "    # z >= 0 ? scale * z : scale * alpha * tf.nn.elu(z)\n",
    "    is_positive = tf.greater_equal(z, 0.0)\n",
    "    return scale * tf.where(is_positive, z, alpha * tf.nn.elu(z))\n",
    "\n",
    "print(scaled_elu(tf.constant(-3.)))\n",
    "print(scaled_elu(tf.constant([-3., -2.5])))\n",
    "\n",
    "scaled_elu_tf = tf.function(scaled_elu)\n",
    "print(scaled_elu_tf(tf.constant(-3.)))\n",
    "print(scaled_elu_tf(tf.constant([-3., -2.5])))\n",
    "\n",
    "print(scaled_elu_tf.python_function is scaled_elu)\n",
    "\n",
    "%timeit scaled_elu(tf.random.normal((1000, 1000)))\n",
    "%timeit scaled_elu_tf(tf.random.normal((1000, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方式二：使用声明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ca15f9cd3ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconverge_to_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mincrement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def converge_to_2(n_iters):\n",
    "    total = tf.constant(0.)\n",
    "    increment = tf.constant(1.)\n",
    "    for _ in range(n_iters):\n",
    "        total += increment\n",
    "        increment /= 2.0\n",
    "    return total\n",
    "\n",
    "print(converge_to_2(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
