{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文主要介绍了模型训练中的各方面内容，包括模型构建、loss、优化器、metrics、正则化、学习率、激活函数、epochs、参数初始化、超参数搜索等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib as mpl\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5、超参数搜索\n",
    "\n",
    "神经网络的灵活性也是它们的主要缺点之一：有许多需要调整的超参数。你不仅可以使用任何可以想象的网络结构，而且即使在简单的MLP中，你也可以更改层数、每层神经元数、每层要使用的激活函数的类型、权重初始化逻辑，以及更多。\n",
    "\n",
    "一种选择是简单地尝试超参数的许多组合，然后查看哪种对验证集最有效（或使用K折交叉验证）。例如我们可以像第2章中一样使用GridSearchCV或RandomizedSearchCV来探索超参数空间。为此我们需要将Keras模型包装在模仿常规ScikitLearn回归器的对象中。\n",
    "\n",
    "下面我们详细介绍在tensorflow中进行超参数搜索的方式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先构建一个基本模型用于之后的超参数搜索。本次我们使用housing数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_valid = scaler.transform(X_valid)\n",
    "x_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "超参数搜索，一种选择是简单地尝试超参数的许多组合，然后查看哪种对验证集最有效（或使用K折交叉验证）。例如我们可以使用GridSearchCV或RandomizedSearchCV来探索超参数空间。为此我们需要将Keras模型包装在模仿常规ScikitLearn回归器的对象中。第一步是创建一个函数，该函数将在给定一组超参数的情况下构建并编译Keras模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=10, learning_rate=0.0001, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics='mse')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们简单看一下只运行一次模型的情况。\n",
    "\n",
    "指定任何超参数，因此它将使用我们在build_model（）中定义的默认超参数。现在，我们可以像常规ScikitLearn回归器一样使用该对象：我们可以使用其fit（）方法进行训练，然后使用其score（）方法进行评估，然后使用predict()方法预测。\n",
    "\n",
    "传递给fit（）方法的任何其他参数都将传递给内部的Keras模型。还要注意，该分数将与MSE相反，因为ScikitLearn希望获得分数，而不是损失（即分数越高越好）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 5.3889 - mse: 5.3889 - val_loss: 33.7463 - val_mse: 33.7463\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.4376 - mse: 4.4376 - val_loss: 29.8043 - val_mse: 29.8043\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.9137 - mse: 4.9137 - val_loss: 26.2964 - val_mse: 26.2964\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.4705 - mse: 3.4705 - val_loss: 22.9076 - val_mse: 22.9076\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.8230 - mse: 2.8230 - val_loss: 19.6532 - val_mse: 19.6532\n",
      "162/162 [==============================] - 0s 866us/step - loss: 2.5638 - mse: 2.5638\n",
      "-2.56375789642334\n",
      "[1.3969504  0.6476435  0.48683828 1.5239983  0.50394875]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(x_train, y_train, epochs=5,\n",
    "             validation_data=(x_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=5)])\n",
    "mse_test = keras_reg.score(x_test, y_test)\n",
    "y_pred = keras_reg.predict(x_test[:5])\n",
    "print(mse_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们开始超参数搜索。\n",
    "\n",
    "我们不想训练和评估这样的单个模型，尽管我们想训练数百个变体，并查看哪种变体在验证集上表现最佳。由于存在许多超参数，因此最好使用随机搜索而不是网格搜索。让我们尝试探索隐藏层的数量、神经元的数量和学习率：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.0012225396848063632, n_hidden=3, n_neurons=28 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "242/242 [==============================] - 3s 4ms/step - loss: 1.0036 - mse: 1.0036 - val_loss: 25377.1113 - val_mse: 25377.1113\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0786 - mse: 1.0786 - val_loss: 34569.7695 - val_mse: 34569.7695\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8845 - mse: 0.8845 - val_loss: 45532.1602 - val_mse: 45532.1602\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2774 - mse: 1.2774 - val_loss: 46359.8516 - val_mse: 46359.8516\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.8796 - mse: 0.8796\n",
      "[CV]  learning_rate=0.0012225396848063632, n_hidden=3, n_neurons=28, total=   5.6s\n",
      "[CV] learning_rate=0.0012225396848063632, n_hidden=3, n_neurons=28 ...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8728 - mse: 0.8728 - val_loss: 39638.6562 - val_mse: 39638.6562\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8481 - mse: 0.8481 - val_loss: 9911.0400 - val_mse: 9911.0400\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8113 - mse: 0.8113 - val_loss: 862.3041 - val_mse: 862.3041\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8672 - mse: 0.8672 - val_loss: 514.7898 - val_mse: 514.7898\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8137 - mse: 0.8137 - val_loss: 4028.4766 - val_mse: 4028.4766\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1980 - mse: 1.1980\n",
      "[CV]  learning_rate=0.0012225396848063632, n_hidden=3, n_neurons=28, total=   3.9s\n",
      "[CV] learning_rate=0.0012225396848063632, n_hidden=3, n_neurons=28 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1315 - mse: 1.1315 - val_loss: 1651.3878 - val_mse: 1651.3878\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 8252.9297 - val_mse: 8252.9297\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8244 - mse: 0.8244 - val_loss: 18577.4727 - val_mse: 18577.4727\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9818 - mse: 0.9818 - val_loss: 28139.5547 - val_mse: 28139.5547\n",
      "121/121 [==============================] - 1s 2ms/step - loss: 0.7206 - mse: 0.7206\n",
      "[CV]  learning_rate=0.0012225396848063632, n_hidden=3, n_neurons=28, total=   3.4s\n",
      "[CV] learning_rate=0.0006409560173237001, n_hidden=3, n_neurons=10 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3363 - mse: 1.3363 - val_loss: 1918.0499 - val_mse: 1918.0499\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0231 - mse: 1.0231 - val_loss: 1424.9712 - val_mse: 1424.9712\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.9292 - mse: 0.9292 - val_loss: 2086.0159 - val_mse: 2086.0159\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8439 - mse: 0.8439 - val_loss: 2269.9465 - val_mse: 2269.9465\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.0130 - mse: 1.0130 - val_loss: 1761.9056 - val_mse: 1761.9056\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9027 - mse: 0.9027\n",
      "[CV]  learning_rate=0.0006409560173237001, n_hidden=3, n_neurons=10, total=   5.7s\n",
      "[CV] learning_rate=0.0006409560173237001, n_hidden=3, n_neurons=10 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9059 - mse: 0.9059 - val_loss: 1956.2373 - val_mse: 1956.2373\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8296 - mse: 0.8296 - val_loss: 1777.4769 - val_mse: 1777.4769\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8369 - mse: 0.8369 - val_loss: 1560.6982 - val_mse: 1560.6982\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7938 - mse: 0.7938 - val_loss: 1364.7266 - val_mse: 1364.7266\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8773 - mse: 0.8773 - val_loss: 1201.9850 - val_mse: 1201.9850\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.1623 - mse: 1.1623\n",
      "[CV]  learning_rate=0.0006409560173237001, n_hidden=3, n_neurons=10, total=   3.3s\n",
      "[CV] learning_rate=0.0006409560173237001, n_hidden=3, n_neurons=10 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2413 - mse: 1.2413 - val_loss: 21296.6211 - val_mse: 21296.6211\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0552 - mse: 1.0552 - val_loss: 8314.9053 - val_mse: 8314.9053\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4406 - mse: 1.4406 - val_loss: 3020.6812 - val_mse: 3020.6812\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1093 - mse: 1.1093 - val_loss: 719.7688 - val_mse: 719.7688\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2839 - mse: 1.2839 - val_loss: 7.5553 - val_mse: 7.5553\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7649 - mse: 0.7649\n",
      "[CV]  learning_rate=0.0006409560173237001, n_hidden=3, n_neurons=10, total=   3.3s\n",
      "[CV] learning_rate=0.001601132636860792, n_hidden=1, n_neurons=19 ....\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6222 - mse: 1.6222 - val_loss: 6819.4644 - val_mse: 6819.4644\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8066 - mse: 0.8066 - val_loss: 131.8757 - val_mse: 131.8757\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8285 - mse: 0.8285 - val_loss: 7646.7168 - val_mse: 7646.7168\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9849 - mse: 0.9849 - val_loss: 17714.7988 - val_mse: 17714.7988\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1791 - mse: 1.1791 - val_loss: 25831.1211 - val_mse: 25831.1211\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.8773 - mse: 0.8773\n",
      "[CV]  learning_rate=0.001601132636860792, n_hidden=1, n_neurons=19, total=   3.3s\n",
      "[CV] learning_rate=0.001601132636860792, n_hidden=1, n_neurons=19 ....\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2212 - mse: 1.2212 - val_loss: 5910.1685 - val_mse: 5910.1685\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8376 - mse: 0.8376 - val_loss: 189.3773 - val_mse: 189.3773\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8107 - mse: 0.8107 - val_loss: 1147.5170 - val_mse: 1147.5170\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8431 - mse: 0.8431 - val_loss: 3998.1169 - val_mse: 3998.1169\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7354 - mse: 0.7354 - val_loss: 7374.3413 - val_mse: 7374.3413\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.3661 - mse: 1.3661\n",
      "[CV]  learning_rate=0.001601132636860792, n_hidden=1, n_neurons=19, total=   3.2s\n",
      "[CV] learning_rate=0.001601132636860792, n_hidden=1, n_neurons=19 ....\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 2s 5ms/step - loss: 1.5607 - mse: 1.5607 - val_loss: 80761.3672 - val_mse: 80761.3672\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1914 - mse: 1.1914 - val_loss: 30415.9395 - val_mse: 30415.9395\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0570 - mse: 1.0570 - val_loss: 12025.3438 - val_mse: 12025.3438\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3898 - mse: 1.3898 - val_loss: 4578.1895 - val_mse: 4578.1895\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9385 - mse: 0.9385 - val_loss: 1434.7507 - val_mse: 1434.7507\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7466 - mse: 0.7466\n",
      "[CV]  learning_rate=0.001601132636860792, n_hidden=1, n_neurons=19, total=   3.7s\n",
      "[CV] learning_rate=0.0003772140246178331, n_hidden=2, n_neurons=21 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9984 - mse: 0.9984 - val_loss: 26858.2285 - val_mse: 26858.2285\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9985 - mse: 0.9985 - val_loss: 27441.8652 - val_mse: 27441.8652\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9256 - mse: 0.9256 - val_loss: 30662.0215 - val_mse: 30662.0215\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8734 - mse: 0.8734 - val_loss: 34749.5547 - val_mse: 34749.5547\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9209 - mse: 0.9209\n",
      "[CV]  learning_rate=0.0003772140246178331, n_hidden=2, n_neurons=21, total=   2.9s\n",
      "[CV] learning_rate=0.0003772140246178331, n_hidden=2, n_neurons=21 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8840 - mse: 0.8840 - val_loss: 110803.9219 - val_mse: 110803.9219\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8595 - mse: 0.8595 - val_loss: 112766.8047 - val_mse: 112766.8047\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8224 - mse: 0.8224 - val_loss: 114806.0938 - val_mse: 114806.0938\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7993 - mse: 0.7993 - val_loss: 116707.0078 - val_mse: 116707.0078\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2539 - mse: 1.2539\n",
      "[CV]  learning_rate=0.0003772140246178331, n_hidden=2, n_neurons=21, total=   3.3s\n",
      "[CV] learning_rate=0.0003772140246178331, n_hidden=2, n_neurons=21 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5775 - mse: 1.5775 - val_loss: 16676.0723 - val_mse: 16676.0723\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0622 - mse: 1.0622 - val_loss: 19523.0938 - val_mse: 19523.0938\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9689 - mse: 0.9689 - val_loss: 24290.8379 - val_mse: 24290.8379\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 29008.6719 - val_mse: 29008.6719\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7692 - mse: 0.7692\n",
      "[CV]  learning_rate=0.0003772140246178331, n_hidden=2, n_neurons=21, total=   2.4s\n",
      "[CV] learning_rate=0.00033190230428052024, n_hidden=3, n_neurons=12 ..\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9686 - mse: 0.9686 - val_loss: 5304.6655 - val_mse: 5304.6655\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0300 - mse: 1.0300 - val_loss: 5084.6489 - val_mse: 5084.6489\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0260 - mse: 1.0260 - val_loss: 4595.3818 - val_mse: 4595.3818\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0883 - mse: 1.0883 - val_loss: 4009.6968 - val_mse: 4009.6968\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1577 - mse: 1.1577 - val_loss: 3338.3350 - val_mse: 3338.3350\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9326 - mse: 0.9326\n",
      "[CV]  learning_rate=0.00033190230428052024, n_hidden=3, n_neurons=12, total=   3.2s\n",
      "[CV] learning_rate=0.00033190230428052024, n_hidden=3, n_neurons=12 ..\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8204 - mse: 0.8204 - val_loss: 9058.4414 - val_mse: 9058.4414\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8482 - mse: 0.8482 - val_loss: 8967.5791 - val_mse: 8967.5791\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8535 - mse: 0.8535 - val_loss: 9072.2207 - val_mse: 9072.2207\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.8992 - mse: 0.899 - 0s 2ms/step - loss: 0.8890 - mse: 0.8890 - val_loss: 9288.4746 - val_mse: 9288.4746\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8064 - mse: 0.8064 - val_loss: 9584.4590 - val_mse: 9584.4590\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2010 - mse: 1.2010\n",
      "[CV]  learning_rate=0.00033190230428052024, n_hidden=3, n_neurons=12, total=   3.1s\n",
      "[CV] learning_rate=0.00033190230428052024, n_hidden=3, n_neurons=12 ..\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0374 - mse: 1.0374 - val_loss: 27822.4102 - val_mse: 27822.4102\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0706 - mse: 1.0706 - val_loss: 35391.9141 - val_mse: 35391.9141\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1327 - mse: 1.1327 - val_loss: 41593.3320 - val_mse: 41593.3320\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1335 - mse: 1.1335 - val_loss: 47257.9219 - val_mse: 47257.9219\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7770 - mse: 0.7770\n",
      "[CV]  learning_rate=0.00033190230428052024, n_hidden=3, n_neurons=12, total=   3.3s\n",
      "[CV] learning_rate=0.002807973542263711, n_hidden=1, n_neurons=25 ....\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1628 - mse: 1.1628 - val_loss: 4786.0522 - val_mse: 4786.0522\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8866 - mse: 0.8866 - val_loss: 17417.5801 - val_mse: 17417.5801\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0194 - mse: 1.0194 - val_loss: 28681.2891 - val_mse: 28681.2891\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8236 - mse: 0.8236 - val_loss: 33836.7305 - val_mse: 33836.7305\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.8724 - mse: 0.8724\n",
      "[CV]  learning_rate=0.002807973542263711, n_hidden=1, n_neurons=25, total=   3.2s\n",
      "[CV] learning_rate=0.002807973542263711, n_hidden=1, n_neurons=25 ....\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0702 - mse: 1.0702 - val_loss: 186734.7031 - val_mse: 186734.7031\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8234 - mse: 0.8234 - val_loss: 129715.3125 - val_mse: 129715.3125\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7974 - mse: 0.7974 - val_loss: 135125.0938 - val_mse: 135125.0938\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7831 - mse: 0.7831 - val_loss: 129130.7578 - val_mse: 129130.7578\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7567 - mse: 0.7567 - val_loss: 128920.3906 - val_mse: 128920.3906\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1430 - mse: 1.1430\n",
      "[CV]  learning_rate=0.002807973542263711, n_hidden=1, n_neurons=25, total=   3.2s\n",
      "[CV] learning_rate=0.002807973542263711, n_hidden=1, n_neurons=25 ....\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1123 - mse: 1.1123 - val_loss: 114411.2812 - val_mse: 114411.2812\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0326 - mse: 1.0326 - val_loss: 135135.9375 - val_mse: 135135.9375\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 136686.7969 - val_mse: 136686.7969\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9899 - mse: 0.9899 - val_loss: 130384.1406 - val_mse: 130384.1406\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7185 - mse: 0.7185\n",
      "[CV]  learning_rate=0.002807973542263711, n_hidden=1, n_neurons=25, total=   3.2s\n",
      "[CV] learning_rate=0.0007636664106224726, n_hidden=2, n_neurons=10 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3014 - mse: 1.3014 - val_loss: 86502.8281 - val_mse: 86502.8281\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1113 - mse: 1.1113 - val_loss: 34039.4922 - val_mse: 34039.4922\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9885 - mse: 0.9885 - val_loss: 14247.1172 - val_mse: 14247.1172\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2355 - mse: 1.2355 - val_loss: 4936.4023 - val_mse: 4936.4023\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9475 - mse: 0.9475 - val_loss: 1036.2821 - val_mse: 1036.2821\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9050 - mse: 0.9050\n",
      "[CV]  learning_rate=0.0007636664106224726, n_hidden=2, n_neurons=10, total=   3.6s\n",
      "[CV] learning_rate=0.0007636664106224726, n_hidden=2, n_neurons=10 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 13126.8926 - val_mse: 13126.8926\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7996 - mse: 0.7996 - val_loss: 13772.2012 - val_mse: 13772.2012\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7723 - mse: 0.7723 - val_loss: 15572.1787 - val_mse: 15572.1787\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8597 - mse: 0.8597 - val_loss: 17655.9922 - val_mse: 17655.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1954 - mse: 1.1954\n",
      "[CV]  learning_rate=0.0007636664106224726, n_hidden=2, n_neurons=10, total=   3.0s\n",
      "[CV] learning_rate=0.0007636664106224726, n_hidden=2, n_neurons=10 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2024 - mse: 1.2024 - val_loss: 121996.8672 - val_mse: 121996.8672\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0239 - mse: 1.0239 - val_loss: 111485.9688 - val_mse: 111485.9688\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0333 - mse: 1.0333 - val_loss: 98485.8359 - val_mse: 98485.8359\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0864 - mse: 1.0864 - val_loss: 89250.4062 - val_mse: 89250.4062\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8671 - mse: 0.8671 - val_loss: 82140.4375 - val_mse: 82140.4375\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7363 - mse: 0.7363\n",
      "[CV]  learning_rate=0.0007636664106224726, n_hidden=2, n_neurons=10, total=   3.5s\n",
      "[CV] learning_rate=0.00042383295739553174, n_hidden=1, n_neurons=19 ..\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8875 - mse: 0.8875 - val_loss: 81637.6953 - val_mse: 81637.6953\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9372 - mse: 0.9372 - val_loss: 73768.2500 - val_mse: 73768.2500\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8987 - mse: 0.8987 - val_loss: 69225.3203 - val_mse: 69225.3203\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8599 - mse: 0.8599 - val_loss: 65853.5078 - val_mse: 65853.5078\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 65608.5703 - val_mse: 65608.5703\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9059 - mse: 0.9059\n",
      "[CV]  learning_rate=0.00042383295739553174, n_hidden=1, n_neurons=19, total=   3.6s\n",
      "[CV] learning_rate=0.00042383295739553174, n_hidden=1, n_neurons=19 ..\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1005 - mse: 1.1005 - val_loss: 135227.8906 - val_mse: 135227.8906\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9550 - mse: 0.9550 - val_loss: 59779.8320 - val_mse: 59779.8320\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9273 - mse: 0.9273 - val_loss: 22947.9355 - val_mse: 22947.9355\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9088 - mse: 0.9088 - val_loss: 6192.6001 - val_mse: 6192.6001\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8400 - mse: 0.8400 - val_loss: 500.9440 - val_mse: 500.9440\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2168 - mse: 1.2168\n",
      "[CV]  learning_rate=0.00042383295739553174, n_hidden=1, n_neurons=19, total=   3.3s\n",
      "[CV] learning_rate=0.00042383295739553174, n_hidden=1, n_neurons=19 ..\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2646 - mse: 1.2646 - val_loss: 3548.6670 - val_mse: 3548.6670\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1386 - mse: 1.1386 - val_loss: 504.5010 - val_mse: 504.5010\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2941 - mse: 1.2941 - val_loss: 106.1763 - val_mse: 106.1763\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0005 - mse: 1.0005 - val_loss: 37.4726 - val_mse: 37.4726\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9831 - mse: 0.9831 - val_loss: 44.3191 - val_mse: 44.3191\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7901 - mse: 0.7901\n",
      "[CV]  learning_rate=0.00042383295739553174, n_hidden=1, n_neurons=19, total=   3.0s\n",
      "[CV] learning_rate=0.0007377729539282017, n_hidden=0, n_neurons=27 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3803 - mse: 1.3803 - val_loss: 4330.8369 - val_mse: 4330.8369\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2302 - mse: 1.2302 - val_loss: 24476.8145 - val_mse: 24476.8145\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9023 - mse: 0.9023 - val_loss: 45094.2500 - val_mse: 45094.2500\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6022 - mse: 1.6022 - val_loss: 58056.2812 - val_mse: 58056.2812\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9231 - mse: 0.9231\n",
      "[CV]  learning_rate=0.0007377729539282017, n_hidden=0, n_neurons=27, total=   2.8s\n",
      "[CV] learning_rate=0.0007377729539282017, n_hidden=0, n_neurons=27 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5885 - mse: 1.5885 - val_loss: 171257.2812 - val_mse: 171257.2812\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1745 - mse: 1.1745 - val_loss: 148254.1094 - val_mse: 148254.1094\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0858 - mse: 1.0858 - val_loss: 127561.3359 - val_mse: 127561.3359\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8794 - mse: 0.8794 - val_loss: 110119.0938 - val_mse: 110119.0938\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8988 - mse: 0.8988 - val_loss: 97097.8906 - val_mse: 97097.8906\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.6100 - mse: 1.6100\n",
      "[CV]  learning_rate=0.0007377729539282017, n_hidden=0, n_neurons=27, total=   3.1s\n",
      "[CV] learning_rate=0.0007377729539282017, n_hidden=0, n_neurons=27 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0191 - mse: 3.0191 - val_loss: 231866.7812 - val_mse: 231866.7812\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5213 - mse: 1.5213 - val_loss: 95149.9219 - val_mse: 95149.9219\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3176 - mse: 1.3176 - val_loss: 32742.6875 - val_mse: 32742.6875\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0643 - mse: 1.0643 - val_loss: 7649.6206 - val_mse: 7649.6206\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9858 - mse: 0.9858 - val_loss: 562.1407 - val_mse: 562.1407\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7575 - mse: 0.7575\n",
      "[CV]  learning_rate=0.0007377729539282017, n_hidden=0, n_neurons=27, total=   2.7s\n",
      "[CV] learning_rate=0.0004812827529905966, n_hidden=2, n_neurons=13 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4325 - mse: 1.4325 - val_loss: 107.5376 - val_mse: 107.5376\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3474 - mse: 1.3474 - val_loss: 59.1098 - val_mse: 59.1098\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2617 - mse: 1.2617 - val_loss: 40.0231 - val_mse: 40.0231\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1354 - mse: 1.1354 - val_loss: 31.4186 - val_mse: 31.4186\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1269 - mse: 1.1269 - val_loss: 27.6772 - val_mse: 27.6772\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9396 - mse: 0.9396\n",
      "[CV]  learning_rate=0.0004812827529905966, n_hidden=2, n_neurons=13, total=   2.6s\n",
      "[CV] learning_rate=0.0004812827529905966, n_hidden=2, n_neurons=13 ...\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9504 - mse: 0.9504 - val_loss: 25468.2422 - val_mse: 25468.2422\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9460 - mse: 0.9460 - val_loss: 27444.6445 - val_mse: 27444.6445\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9112 - mse: 0.9112 - val_loss: 32451.4141 - val_mse: 32451.4141\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8070 - mse: 0.8070 - val_loss: 37639.8008 - val_mse: 37639.8008\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2011 - mse: 1.2011\n",
      "[CV]  learning_rate=0.0004812827529905966, n_hidden=2, n_neurons=13, total=   2.5s\n",
      "[CV] learning_rate=0.0004812827529905966, n_hidden=2, n_neurons=13 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1446 - mse: 1.1446 - val_loss: 67661.6562 - val_mse: 67661.6562\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2751 - mse: 1.2751 - val_loss: 42446.3594 - val_mse: 42446.3594\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9315 - mse: 0.9315 - val_loss: 29311.6816 - val_mse: 29311.6816\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0818 - mse: 1.0818 - val_loss: 21369.0430 - val_mse: 21369.0430\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9288 - mse: 0.9288 - val_loss: 16616.7598 - val_mse: 16616.7598\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.7450 - mse: 0.7450\n",
      "[CV]  learning_rate=0.0004812827529905966, n_hidden=2, n_neurons=13, total=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ff04fe68070>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-92a149dccc40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m rnd_search_cv.fit(x_train, x_train, epochs=5,\n\u001b[0m\u001b[1;32m     12\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                   callbacks=[keras.callbacks.EarlyStopping(patience=3)])\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ff04fe68070>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(10, 30),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-3),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(x_train, x_train, epochs=5,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搜索可能持续数小时，具体时间取决于硬件、数据集的大小、模型的复杂性以及n_iter和cv的值。当结束时，你可以访问找到的最佳参数、最佳分数和经过训练的Keras模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.011135720468105712, 'n_hidden': 2, 'n_neurons': 93}\n",
      "-0.8941203554471334\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-23cd01893dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_valid = scaler.transform(X_valid)\n",
    "x_test = scaler.transform(X_test) \n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=10, learning_rate=0.0001, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics='mse')\n",
    "    return model\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(10, 30),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-3),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(x_train, x_train, epochs=5,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
