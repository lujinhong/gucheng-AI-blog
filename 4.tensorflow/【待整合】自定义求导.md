```python
import matplotlib as mpl
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import sklearn
import pandas as pd
import os
import sys
import time
import tensorflow as tf

from tensorflow import keras

print(tf.__version__)
print(sys.version_info)
for module in mpl, np, pd, sklearn, tf, keras:
    print(module.__name__, module.__version__)
```

    2.0.0-alpha0
    sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)
    matplotlib 3.0.3
    numpy 1.16.2
    pandas 0.24.2
    sklearn 0.20.3
    tensorflow 2.0.0-alpha0
    tensorflow.python.keras.api._v2.keras 2.2.4-tf



```python
from sklearn.datasets import fetch_california_housing

housing = fetch_california_housing()
print(housing.DESCR)
print(housing.data.shape)
print(housing.target.shape)
```

    .. _california_housing_dataset:
    
    California Housing dataset
    --------------------------
    
    **Data Set Characteristics:**
    
        :Number of Instances: 20640
    
        :Number of Attributes: 8 numeric, predictive attributes and the target
    
        :Attribute Information:
            - MedInc        median income in block
            - HouseAge      median house age in block
            - AveRooms      average number of rooms
            - AveBedrms     average number of bedrooms
            - Population    block population
            - AveOccup      average house occupancy
            - Latitude      house block latitude
            - Longitude     house block longitude
    
        :Missing Attribute Values: None
    
    This dataset was obtained from the StatLib repository.
    http://lib.stat.cmu.edu/datasets/
    
    The target variable is the median house value for California districts.
    
    This dataset was derived from the 1990 U.S. census, using one row per census
    block group. A block group is the smallest geographical unit for which the U.S.
    Census Bureau publishes sample data (a block group typically has a population
    of 600 to 3,000 people).
    
    It can be downloaded/loaded using the
    :func:`sklearn.datasets.fetch_california_housing` function.
    
    .. topic:: References
    
        - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,
          Statistics and Probability Letters, 33 (1997) 291-297
    
    (20640, 8)
    (20640,)



```python
from sklearn.model_selection import train_test_split

x_train_all, x_test, y_train_all, y_test = train_test_split(
    housing.data, housing.target, random_state = 7)
x_train, x_valid, y_train, y_valid = train_test_split(
    x_train_all, y_train_all, random_state = 11)
print(x_train.shape, y_train.shape)
print(x_valid.shape, y_valid.shape)
print(x_test.shape, y_test.shape)

```

    (11610, 8) (11610,)
    (3870, 8) (3870,)
    (5160, 8) (5160,)



```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_valid_scaled = scaler.transform(x_valid)
x_test_scaled = scaler.transform(x_test)
```


```python
# metric使用

metric = keras.metrics.MeanSquaredError()
print(metric([5.], [2.]))
print(metric([0.], [1.]))
print(metric.result())

metric.reset_states()
metric([1.], [3.])
print(metric.result())
```

    tf.Tensor(9.0, shape=(), dtype=float32)
    tf.Tensor(5.0, shape=(), dtype=float32)
    tf.Tensor(5.0, shape=(), dtype=float32)
    tf.Tensor(4.0, shape=(), dtype=float32)



```python
# 1. batch 遍历训练集 metric
#    1.1 自动求导
# 2. epoch结束 验证集 metric

epochs = 100
batch_size = 32
steps_per_epoch = len(x_train_scaled) // batch_size
optimizer = keras.optimizers.SGD()
metric = keras.metrics.MeanSquaredError()

def random_batch(x, y, batch_size=32):
    idx = np.random.randint(0, len(x), size=batch_size)
    return x[idx], y[idx]

model = keras.models.Sequential([
    keras.layers.Dense(30, activation='relu',
                       input_shape=x_train.shape[1:]),
    keras.layers.Dense(1),
])

for epoch in range(epochs):
    metric.reset_states()
    for step in range(steps_per_epoch):
        x_batch, y_batch = random_batch(x_train_scaled, y_train,
                                        batch_size)
        with tf.GradientTape() as tape:
            y_pred = model(x_batch)
            y_pred = tf.squeeze(y_pred, 1)
            loss = keras.losses.mean_squared_error(y_batch, y_pred)
            metric(y_batch, y_pred)
        grads = tape.gradient(loss, model.variables)
        grads_and_vars = zip(grads, model.variables)
        optimizer.apply_gradients(grads_and_vars)
        print("\rEpoch", epoch, " train mse:",
              metric.result().numpy(), end="")
    y_valid_pred = model(x_valid_scaled)
    y_valid_pred = tf.squeeze(y_valid_pred, 1)
    valid_loss = keras.losses.mean_squared_error(y_valid_pred, y_valid)
    print("\t", "valid mse: ", valid_loss.numpy())
        

```

    Epoch 0  train mse: 2.104944	 valid mse:  1.152736027725499
    Epoch 1  train mse: 0.91872215	 valid mse:  0.8896286160432914e: 0.99164706
    Epoch 2  train mse: 0.7998	 valid mse:  0.8209366091379866
    Epoch 3  train mse: 0.7054345	 valid mse:  0.7788972844132297se: 0.7028327
    Epoch 4  train mse: 0.6893323	 valid mse:  0.7392967041328761
    Epoch 5  train mse: 0.6838636	 valid mse:  0.7068141334218119
    Epoch 6  train mse: 0.6288853	 valid mse:  0.676981339116993
    Epoch 7  train mse: 0.6157134	 valid mse:  0.6511911645713215
    Epoch 8  train mse: 0.5851619	 valid mse:  0.6293785540415384
    Epoch 9  train mse: 0.5706613	 valid mse:  0.6118971719218474
    Epoch 10  train mse: 0.5402706	 valid mse:  0.5952621731378016
    Epoch 11  train mse: 0.54052293	 valid mse:  0.5809133897694022
    Epoch 12  train mse: 0.53637516	 valid mse:  0.5675094480108381
    Epoch 13  train mse: 0.51985973	 valid mse:  0.5559689667789274
    Epoch 14  train mse: 0.515164	 valid mse:  0.5467192232581582se: 0.5145796
    Epoch 15  train mse: 0.479978	 valid mse:  0.5379682506321743
    Epoch 16  train mse: 0.50999725	 valid mse:  0.526679171092507
    Epoch 17  train mse: 0.46633324	 valid mse:  0.5203992950389394
    Epoch 18  train mse: 0.477215	 valid mse:  0.5148747847712059
    Epoch 19  train mse: 0.46417397	 valid mse:  0.5108684664543097
    Epoch 20  train mse: 0.48178193	 valid mse:  0.5032346237395398
    Epoch 21  train mse: 0.46185252	 valid mse:  0.4973093740644174
    Epoch 22  train mse: 0.46274024	 valid mse:  0.49307524893381793
    Epoch 23  train mse: 0.46644682	 valid mse:  0.49080667365353564
    Epoch 24  train mse: 0.4432642	 valid mse:  0.48643213564593407
    Epoch 25  train mse: 0.45090625	 valid mse:  0.4818171441196208
    Epoch 26  train mse: 0.4488629	 valid mse:  0.48045542258747753
    Epoch 27  train mse: 0.44181794	 valid mse:  0.47517768752912226
    Epoch 28  train mse: 0.45161572	 valid mse:  0.47219569787517995
    Epoch 29  train mse: 0.46572572	 valid mse:  0.47206957035969616
    Epoch 30  train mse: 0.43808585	 valid mse:  0.466308046997983
    Epoch 31  train mse: 0.43751845	 valid mse:  0.4648199179876645
    Epoch 32  train mse: 0.41373685	 valid mse:  0.4624802952284964
    Epoch 33  train mse: 0.42936268	 valid mse:  0.4591652727317869
    Epoch 34  train mse: 0.43549538	 valid mse:  0.4564868130596492
    Epoch 35  train mse: 0.41336903	 valid mse:  0.45607885896796246
    Epoch 36  train mse: 0.43046692	 valid mse:  0.4519846246128156
    Epoch 37  train mse: 0.42912322	 valid mse:  0.4499456875558165
    Epoch 38  train mse: 0.4072349	 valid mse:  0.44929765676556316
    Epoch 39  train mse: 0.41295713	 valid mse:  0.4469238782653186
    Epoch 40  train mse: 0.40867978	 valid mse:  0.44669546120138526
    Epoch 41  train mse: 0.40263054	 valid mse:  0.44395406849183744
    Epoch 42  train mse: 0.3994772	 valid mse:  0.44228469782954477
    Epoch 43  train mse: 0.40704134	 valid mse:  0.4399421895359583
    Epoch 44  train mse: 0.40135807	 valid mse:  0.4388833924376266
    Epoch 45  train mse: 0.41037697	 valid mse:  0.43674971655216643
    Epoch 46  train mse: 0.41439566	 valid mse:  0.4355941281269153
    Epoch 47  train mse: 0.40962568	 valid mse:  0.43441572506192067
    Epoch 48  train mse: 0.39851716	 valid mse:  0.4328888719464885
    Epoch 49  train mse: 0.40331197	 valid mse:  0.43122653409416056.39889443
    Epoch 50  train mse: 0.42073172	 valid mse:  0.4294852504029208
    Epoch 51  train mse: 0.40786812	 valid mse:  0.4287425712693342
    Epoch 52  train mse: 0.41433766	 valid mse:  0.42699564555562336
    Epoch 53  train mse: 0.41345644	 valid mse:  0.42702381501432485
    Epoch 54  train mse: 0.41383186	 valid mse:  0.4242592538388384
    Epoch 55  train mse: 0.40154928	 valid mse:  0.4231782697883574
    Epoch 56  train mse: 0.3922401	 valid mse:  0.4234387693958411
    Epoch 57  train mse: 0.40719342	 valid mse:  0.42240796143768206
    Epoch 58  train mse: 0.3852795	 valid mse:  0.42158149302297054
    Epoch 59  train mse: 0.4099938	 valid mse:  0.4208094741191737
    Epoch 60  train mse: 0.38776717	 valid mse:  0.4194609600149003
    Epoch 61  train mse: 0.41638777	 valid mse:  0.41710019076108146
    Epoch 62  train mse: 0.39179453	 valid mse:  0.4178874808168511
    Epoch 63  train mse: 0.39036337	 valid mse:  0.4163798249391438
    Epoch 64  train mse: 0.39790294	 valid mse:  0.41494463710357116
    Epoch 65  train mse: 0.38758674	 valid mse:  0.41396833987338855
    Epoch 66  train mse: 0.41155463	 valid mse:  0.41337588215185694
    Epoch 67  train mse: 0.38826972	 valid mse:  0.4119882916304662
    Epoch 68  train mse: 0.38930225	 valid mse:  0.4114479417128327
    Epoch 69  train mse: 0.38810772	 valid mse:  0.411542709680951
    Epoch 70  train mse: 0.38471222	 valid mse:  0.41061533896534735
    Epoch 71  train mse: 0.39543507	 valid mse:  0.40890688181233065
    Epoch 72  train mse: 0.37729052	 valid mse:  0.40842533312435475
    Epoch 73  train mse: 0.38770664	 valid mse:  0.4077723521963252
    Epoch 74  train mse: 0.3808367	 valid mse:  0.40831397397351854
    Epoch 75  train mse: 0.37124214	 valid mse:  0.4079214262858768
    Epoch 76  train mse: 0.38131458	 valid mse:  0.40689089063270617
    Epoch 77  train mse: 0.39142957	 valid mse:  0.40461315441581913
    Epoch 78  train mse: 0.3847341	 valid mse:  0.40419731915176016
    Epoch 79  train mse: 0.3856133	 valid mse:  0.40517933238266035
    Epoch 80  train mse: 0.3826249	 valid mse:  0.4036865978866542
    Epoch 81  train mse: 0.38086516	 valid mse:  0.4023046808844443
    Epoch 82  train mse: 0.37560025	 valid mse:  0.402186101305847
    Epoch 83  train mse: 0.38003284	 valid mse:  0.40099077221170687
    Epoch 84  train mse: 0.39618662	 valid mse:  0.400377808022975
    Epoch 85  train mse: 0.37961963	 valid mse:  0.400851183088995
    Epoch 86  train mse: 0.38147828	 valid mse:  0.39947008166537423
    Epoch 87  train mse: 0.39104906	 valid mse:  0.4000694746090793
    Epoch 88  train mse: 0.39817396	 valid mse:  0.3983560495787654
    Epoch 89  train mse: 0.39617527	 valid mse:  0.39896695078765876
    Epoch 90  train mse: 0.38800916	 valid mse:  0.398446036644316
    Epoch 91  train mse: 0.38297555	 valid mse:  0.39777756211776305
    Epoch 92  train mse: 0.3598824	 valid mse:  0.3979537550166713
    Epoch 93  train mse: 0.36405742	 valid mse:  0.39890728342281334
    Epoch 94  train mse: 0.36883098	 valid mse:  0.3985041265349875
    Epoch 95  train mse: 0.38816872	 valid mse:  0.39594222937687445
    Epoch 96  train mse: 0.3903994	 valid mse:  0.3949346546069753
    Epoch 97  train mse: 0.36976993	 valid mse:  0.39451668831237774
    Epoch 98  train mse: 0.3692444	 valid mse:  0.39590326441132334se: 0.36070287
    Epoch 99  train mse: 0.36694872	 valid mse:  0.3949503509951996



```python

```
