{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304f1f02-0f24-4526-b4bd-8e640321849e",
   "metadata": {},
   "source": [
    "在本文中，我们使用tensorflow2.x实现了lenet-5，用于mnist的识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428d4c81-56dc-4197-aaf6-0c80f64b573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0ce24-8bad-4150-bdbb-f9b0849826e4",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "我们先载入mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "191719d5-5427-4575-8cb3-25263dac30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d0ec7-fcc2-4b91-a1a0-4fb37cf3d032",
   "metadata": {},
   "source": [
    "我们把特征数据增加一个纬度，用于LeNet5的输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e108f23-4698-4c8b-84f5-b12337f1bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28, 1) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceaf7cc-522b-4f7b-87ff-e3adf4ff2915",
   "metadata": {},
   "source": [
    "特征数据归一化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5ed8c9d-0015-4ebd-be2d-5dcc2ec9182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e499fdd-4f49-4dc1-aa9b-333d94418ca2",
   "metadata": {},
   "source": [
    "标签做onehot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f0a49ec-3709-42b7-95c4-db3b6df9df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(pd.get_dummies(y_train))\n",
    "y_test = np.array(pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067576e3-b0d5-4897-aed0-58d94c01cd20",
   "metadata": {},
   "source": [
    "# 构建模型\n",
    "我们使用sequential构建LeNet-5模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52475146-7e68-4837-9618-999c6b957c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5,5), input_shape=(28,28,1), padding='same', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=120, kernel_size=(5,5), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(84, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185006e5-4b82-4deb-ba21-bb82486cc94f",
   "metadata": {},
   "source": [
    "我们看一下模型的详细情况，包括每一层的输出大小，可训练参数数量，模型的总参数等。\n",
    "\n",
    "总结\n",
    "* 每个卷积层的大小是滤波器的大小（k*k) * 滤波器的数量 * 输入的通道数量（即上一层输出的通道数量）。\n",
    "* 每个滤波器内的多个通道得到的最终结果，会按位相加得到最终一个输出矩阵，所以每一个卷积层输出filter个通道，这也是下一层的输入通道数量。\n",
    "\n",
    "\n",
    "关于参数数量，我们做一个详细的解释：\n",
    "\n",
    "* 第一个卷积层，每个滤波器的大小为5*5，总共有6个，加上偏置量，所以参数数量为5*5*6+6=156。如果输入图片为3通道图片，则参数个数为5*5*3*6+6=456。也就是说每个卷积核，他的厚度是与前一层的输入相同的。\n",
    "* 第二个卷积层，每个滤波器大小也是5*5，总共16个，上一层的输出通道是6，所以总的参数数量是5*5*6*16+16=2416。\n",
    "* 第三个卷积层，每个滤波器大小也是5*5，总共120个，上一层输出通道是16，所以总的参数数量是5*5*16*12+120=48120。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8e0fe35-7c46-486b-86a2-398cd44fd269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_22 (Averag (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_23 (Averag (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3c22122-a2a7-4616-99de-7c14795076f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a8ec81e-7de8-477e-8946-b912d172767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee84505-941f-466f-bde8-0d1f44c00b0f",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ea5b737-3c09-42cf-acda-6899696804c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0638 - acc: 0.9805 - val_loss: 0.0618 - val_acc: 0.9801\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0548 - acc: 0.9832 - val_loss: 0.0515 - val_acc: 0.9830\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0480 - acc: 0.9851 - val_loss: 0.0727 - val_acc: 0.9763\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0431 - acc: 0.9870 - val_loss: 0.0420 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0390 - acc: 0.9881 - val_loss: 0.0461 - val_acc: 0.9851\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0347 - acc: 0.9889 - val_loss: 0.0394 - val_acc: 0.9866\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0309 - acc: 0.9904 - val_loss: 0.0434 - val_acc: 0.9851\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0279 - acc: 0.9908 - val_loss: 0.0373 - val_acc: 0.9879\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.0353 - val_acc: 0.9886\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0361 - val_acc: 0.9876\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844930a8-7ce3-4d45-866b-9feb5047c25a",
   "metadata": {},
   "source": [
    "准确率可以打到98%以上。\n",
    "\n",
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "368d756f-accf-47b9-8068-9e7cf058526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61656464-1890-4a8e-a14e-76e6ecb520de",
   "metadata": {},
   "source": [
    "# 加载模型&预测\n",
    "我们使用上面的模型对手写数字进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f3208d3-dc13-4b22-80f7-457b582d0a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f602c0a07f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQbklEQVR4nO3dfYxc5XXH8d+Z8S672Mb2Gr9sjXkJNShOGkyycYOg1FFeCqQq8AdRSEvcitaJGiKi5I+Q5I+gSo1c1IRWaYVkihNT8SIkoLiBNLgWLaFKUxbkgqkLdsDYxsZrXr3GNrveOf1jh3QDe88dZu7MHfN8P9JqdufMnTke72/vzDz3uY+5uwC891XKbgBAZxB2IBGEHUgEYQcSQdiBRMzo5IP1Vvu9v2dOJx8SSMqR8dc1NnHEpqu1FHYzu0jS30qqSvoHd18b3b6/Z47OO/ULrTwkgMDPd92aWWv6ZbyZVSX9vaSLJS2XdKWZLW/2/gC0Vyvv2VdK2uHuz7r7mKQ7JV1aTFsAitZK2JdI2j3l5z31636Nma0xs2EzGx6bONLCwwFoRSthn+5DgHcce+vu69x9yN2Heqv9LTwcgFa0EvY9kpZO+fkUSXtbawdAu7QS9kclLTOzM8ysV9LnJG0spi0ARWt66M3dj5nZNZJ+qsmht/Xu/lRhnQEoVEvj7O7+gKQHCuoFQBtxuCyQCMIOJIKwA4kg7EAiCDuQCMIOJKKj89nRpEr8N/nY/FmZNa9OO7X5PcEm4jMjz3jtcHZx/FjB3XQ/9uxAIgg7kAjCDiSCsAOJIOxAIgg7kAiG3johZ+hsYmBmS3c/Y0f2OUMmDhxo6b672YzBxTk3yP719v4T4m1rtSY66m7s2YFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSATj7EXoiZ9GOxQve1X95cGwnjdW/vSNH8usLTg7XiK75t07BdZzenv16YGwftr945m1vu3748eelbN60XE4RZY9O5AIwg4kgrADiSDsQCIIO5AIwg4kgrADiWCcvVG9PZklGw1OWSzp0IrfCOsvXFgN6wPL54b1G5bdnlkb9/i+y1SxeM54VfGpoifOisfhv/v8H2bWlmyLx8lrfb1hvXIcjrO3FHYz2ylpVNKEpGPuPlREUwCKV8Se/ePu/lIB9wOgjXjPDiSi1bC7pAfN7DEzWzPdDcxsjZkNm9nw2ER8jDiA9mn1Zfz57r7XzBZK2mRm/+vuD0+9gbuvk7ROkub0LY4/cQHQNi3t2d19b/1yRNK9klYW0RSA4jUddjObaWaz3/pe0qclbS2qMQDFauVl/CJJ95rZW/dzu7v/SyFddSGfkf13MW9G+Njs+G/qvPe/HNY/f/qjYf2vtv9e9n1/Znu47fHsu8/9V1g/siD7XWPt0BvxnVdPbqalrtZ02N39WUnnFNgLgDZi6A1IBGEHEkHYgUQQdiARhB1IBFNcG1Q5dDSzlnfa4YGf7QnrvunNsP6TA3PD+vzZL2bWjv3uueG2tWrO3/ucccW+Z3JOyfx69mmyn/vaB8Nte1a8GtbnVh4J65Xx7OYtmLIsKWdy7fGJPTuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4lgnL1BXgkGnHNOK5w3Dn/slPlhfeJDp4b1aFC496V4Kmfl5Xi56Nqrr4X13V9aEdYPfyT7VGTf/PA94bZLeuJx9h++el5Yn/lC9hNjfX3htjZ2/J0qOg97diARhB1IBGEHEkHYgUQQdiARhB1IBGEHEsE4exEq8d/M2swTwnr1yHhY79kdr5vpR4JltSrxks27r1oW1kfPjnv72gX3h/Vz+p/PrG0e/UC47d2rPhTW/XC8nNiiBfuyt50ZH/tgh+NzDByP2LMDiSDsQCIIO5AIwg4kgrADiSDsQCIIO5AIxtkb1ZP9VNmheLy38vpoWK+9/EpYH7nqo2F9bG72XPvDi+IzoP/Rxf8W1s+bGS/5/B9vnBXW1664MLPmHvc29tGlYd1ytp9xMHusvHIw/j97L8rds5vZejMbMbOtU64bMLNNZra9fjmvvW0CaFUjL+N/JOmit113naTN7r5M0ub6zwC6WG7Y3f1hSW9/nXmppA317zdIuqzYtgAUrdkP6Ba5+z5Jql8uzLqhma0xs2EzGx6bSO99EtAt2v5pvLuvc/chdx/qrcaTDwC0T7Nh329mg5JUvxwpriUA7dBs2DdKWl3/frWk+4ppB0C75I6zm9kdklZJOtnM9kj6jqS1ku4ys6sl7ZJ0RTub7IhgHF2Kx9Lf+K3BcNsD58RrgR9dHn+WccNv3xbWL5v5WmatavHf8/88OhHWP//An4d11eKy/jK7NHtHPNd+yQ+3hvW8cfrKSbOzt52bXZOUuxaAann/8O6TG3Z3vzKj9ImCewHQRhwuCySCsAOJIOxAIgg7kAjCDiSCKa51tb7esF4Nht5Gl8ZP40f+IB5Cunbxv4b1cY+HqB4Nz3ocD63lufMzf9fS9pGHDi0P6zefGg/4VA8Hy2hLmvlCdm3wx7vCbWXxfXt/fHrwbhyaY88OJIKwA4kg7EAiCDuQCMIOJIKwA4kg7EAiLG+aYJHm9C328079Qscer1DBuKuNxcsaq5bzHHfhmOyv5I03j8f/9tcvPCOztvov/jncdmXfc2G9YvHzuvHgiszaPTd9PNx28Me7w7rPPjGs506RbVPufr7rVr1+9MVp/9PYswOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kAjG2btBzli2ZsTz2dvqWM58+Lzfn0r2/mR8YXw651pv/O+2nOMXPvWDn2XWjtbi03v/5IbspaYlaf6/x+PwtZPnhPW8Zb6bxTg7AMIOpIKwA4kg7EAiCDuQCMIOJIKwA4ngvPFFaHWcPG/7MuUsZZ0rGIfv3XmgtbvOmUt/1w8+mVm75Zt/E2972qqwPnAkHid3mxvWy/gfz92zm9l6Mxsxs61TrrvezF4wsy31r0va2yaAVjXyMv5Hki6a5vob3X1F/euBYtsCULTcsLv7w5Je6UAvANqolQ/orjGzJ+ov8+dl3cjM1pjZsJkNj02053hgAPmaDftNks6UtELSPknfy7qhu69z9yF3H+qt9jf5cABa1VTY3X2/u0+4e03SzZJWFtsWgKI1FXYzG5zy4+WS4jWJAZQudxDVzO6QtErSyWa2R9J3JK0ysxWSXNJOSV9sX4vHgbw53XnnEO/mcfZWBccY1Abi+ezeEx+fUN3/Wlif90z2wvXPjC8Mt738s9lz4SXppy9eENYXPhiv/x7Nd2/XXPfcsLv7ldNcfUsbegHQRhwuCySCsAOJIOxAIgg7kAjCDiSCKa5or2DYsXJ0LNzUW5xeOzY3e/tHDp4Vbvv7c7eE9fvm/05Y9zdz/m3VYAnwcMvmsWcHEkHYgUQQdiARhB1IBGEHEkHYgUQQdiARjLN3wnv5VNM5bPRw89vmLRedY9a1ezJrn5zzVLjttbf+WVh/3x3Ph3VfOBDWKwc7f4o29uxAIgg7kAjCDiSCsAOJIOxAIgg7kAjCDiSCcfYi5IyD21i8tLCOZJ/yWJI00dp4c1tV42METrg9e173t5fe39pDKz6F98jErMzaV+7403Db37xlZ/zglZz9ZK0W1/NOP94G7NmBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgE4+wN8ln9mbXKywfDbV9atTSsz/uTeHnfLy19JKyXqc/iYwhGjmUvy3zF/V8Jt628GR+/4DmnAeh9JXtfljuO3tsTP3b/CfH2ecdWlCB3z25mS83sITPbZmZPmdm19esHzGyTmW2vX85rf7sAmtXIy/hjkr7u7u+X9DFJXzaz5ZKuk7TZ3ZdJ2lz/GUCXyg27u+9z98fr349K2iZpiaRLJW2o32yDpMva1COAAryrD+jM7HRJ50r6haRF7r5PmvyDIGlhxjZrzGzYzIbHJjp/3i0AkxoOu5nNknS3pK+6e/yJ1BTuvs7dh9x9qLea/SEXgPZqKOxm1qPJoN/m7vfUr95vZoP1+qCkkfa0CKAIuUNvZmaSbpG0zd2/P6W0UdJqSWvrl/e1pcMuYYdzpqEGTtp1NKy/+E+nhfVvLLiq6ccu24n7s4fPzl6/Jdy2djR+zi1nem3lpOwprrXBad91/v99500r7sKhtTyNjLOfL+kqSU+a2Zb6dd/SZMjvMrOrJe2SdEVbOgRQiNywu/sjyl4f/hPFtgOgXThcFkgEYQcSQdiBRBB2IBGEHUgEU1wbFZwaOG+6Y++zB8L6kh3xaYdrB0fDejezvr7MWu0DZ8YbV3OmuOY8dm0i+xaV196INy7hVM/txp4dSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEMM5ehJzlefPG4f3EnPri4/fEvR48NZVXD3WuEbBnB1JB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYyzd0LOOLwdipfFimd1A41hzw4kgrADiSDsQCIIO5AIwg4kgrADiSDsQCJyw25mS83sITPbZmZPmdm19euvN7MXzGxL/euS9rcLoFmNHFRzTNLX3f1xM5st6TEz21Sv3ejuf92+9gAUpZH12fdJ2lf/ftTMtkla0u7GABTrXb1nN7PTJZ0r6Rf1q64xsyfMbL2ZTXvuJDNbY2bDZjY8NhEfFgqgfRoOu5nNknS3pK+6+0FJN0k6U9IKTe75vzfddu6+zt2H3H2ot9rfescAmtJQ2M2sR5NBv83d75Ekd9/v7hPuXpN0s6SV7WsTQKsa+TTeJN0iaZu7f3/K9YNTbna5pK3FtwegKI18Gn++pKskPWlmW+rXfUvSlWa2QpMr5+6U9MU29AegII18Gv+Ipp9S/UDx7QBoF46gAxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEmLt37sHMDkh6fspVJ0t6qWMNvDvd2lu39iXRW7OK7O00d18wXaGjYX/Hg5sNu/tQaQ0EurW3bu1Lordmdao3XsYDiSDsQCLKDvu6kh8/0q29dWtfEr01qyO9lfqeHUDnlL1nB9AhhB1IRClhN7OLzOxpM9thZteV0UMWM9tpZk/Wl6EeLrmX9WY2YmZbp1w3YGabzGx7/XLaNfZK6q0rlvEOlhkv9bkre/nzjr9nN7OqpGckfUrSHkmPSrrS3f+no41kMLOdkobcvfQDMMzsQkmHJN3q7h+sX3eDpFfcfW39D+U8d/9Gl/R2vaRDZS/jXV+taHDqMuOSLpP0xyrxuQv6+qw68LyVsWdfKWmHuz/r7mOS7pR0aQl9dD13f1jSK2+7+lJJG+rfb9DkL0vHZfTWFdx9n7s/Xv9+VNJby4yX+twFfXVEGWFfImn3lJ/3qLvWe3dJD5rZY2a2puxmprHI3fdJk788khaW3M/b5S7j3UlvW2a8a567ZpY/b1UZYZ9uKaluGv87390/LOliSV+uv1xFYxpaxrtTpllmvCs0u/x5q8oI+x5JS6f8fIqkvSX0MS1331u/HJF0r7pvKer9b62gW78cKbmfX+mmZbynW2ZcXfDclbn8eRlhf1TSMjM7w8x6JX1O0sYS+ngHM5tZ/+BEZjZT0qfVfUtRb5S0uv79akn3ldjLr+mWZbyzlhlXyc9d6cufu3vHvyRdoslP5H8p6dtl9JDR1/sk/Xf966mye5N0hyZf1o1r8hXR1ZLmS9osaXv9cqCLevtHSU9KekKTwRosqbcLNPnW8AlJW+pfl5T93AV9deR543BZIBEcQQckgrADiSDsQCIIO5AIwg4kgrADiSDsQCL+D6nw7xM19VqlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('3.png', 0)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f53a855-d71b-48db-8180-ab3536d89296",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (28,28))\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "img = img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3687e51-31d2-4492-8c83-57cd0a60573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9507696e-09 7.0097293e-08 1.7773251e-06 9.9997258e-01 3.6114369e-09\n",
      "  1.9603556e-05 2.9246516e-10 1.3854858e-06 7.9077779e-07 3.7732302e-06]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "my_model = tf.keras.models.load_model('mnist.h5')\n",
    "predict = my_model.predict(img)\n",
    "print(predict)\n",
    "print(np.argmax(predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7c2b6-1fe8-456d-ad48-8f486d5cab4a",
   "metadata": {},
   "source": [
    "# 手动训练模型\n",
    "上述方式使用keras定义网络结构并compile()后，直接使用fit()来进行模型训练。\n",
    "\n",
    "如果我们需要对训练过程有更细节的调整可以手动定义训练过程。\n",
    "\n",
    "对于数据而言，我们可以使用传统的numpy/pandas的数据处理方式，但如果数据量太大时，可以使用tf.dataset的方式处理。下面我们先介绍numpy/pandas的处理方式，然后再介绍tf.dataset的处理方式。\n",
    "\n",
    "## numpy/pandas方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe2ab1-e8a2-42bd-944b-00dffd802a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000, 28, 28) 0 255\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_143 (Conv2D)          (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_94 (Averag (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_95 (Averag (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 - mean: 0.0155 - mean_absolute_error: 0.0320 - categorical_accuracy: 0.8792 - precision_36: 0.9509\n",
      "60000/60000 - mean: 0.0155 - mean_absolute_error: 0.0320 - categorical_accuracy: 0.8792 - precision_36: 0.9509\n",
      "Epoch 2/5\n",
      "18112/60000 - mean: 0.0051 - mean_absolute_error: 0.0098 - categorical_accuracy: 0.9670 - precision_36: 0.9717"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics, losses\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = datasets.mnist.load_data()\n",
    "print('datasets:', x_train.shape, x_train.shape, x_train.min(), x_train.max())\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "y_train = np.array(pd.get_dummies(y_train))\n",
    "y_test = np.array(pd.get_dummies(y_test))\n",
    "\n",
    "\n",
    "# CNN不加L2\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5,5), input_shape=(28,28,1), padding='same', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=120, kernel_size=(5,5), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(84, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "model.summary()\n",
    "\n",
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return x_train[idx], y_train[idx]\n",
    "\n",
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(x_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "\n",
    "# 补充一个关于accuracy的说明：\n",
    "# * 如果模型输出是一个数值，而标签也是一个数值，此时可以直接使用metrics=['accuracy']或者metrics= [keras.metrics.Accuracy()]\n",
    "# * 如果模型输出是一个多分类的概率列表，标签是一个onehot后的列表，则此时使用category_accuracy或者keras.metrics.CategoricalAccuracy()\n",
    "# * 如果模型输出是一个多分类的概率列表，标签是一个数值，则此时使用sparse_category_accuracy或者keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "metrics = [keras.metrics.MeanAbsoluteError(), keras.metrics.CategoricalAccuracy(), keras.metrics.Precision()]\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(x_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        #如果model各层中有加入正则化：\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()\n",
    "        \n",
    "\n",
    "# 测试误差\n",
    "print('Test metrics: ')\n",
    "y_test_pred = model(x_test)\n",
    "for metric in metrics:\n",
    "    print(metric.name, metric(y_test, y_test_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9b269-2bcd-4153-b803-2c993765c618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b07c8-9afb-4c04-9e7e-697e0774024b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
