{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61422d37",
   "metadata": {},
   "source": [
    "\n",
    "本文介绍了：\n",
    "1. 如何将多个标签做onehot，比如说总共有1000个标签，用户带了其中100个标签，那就是一个1000维的feautre，其中100维=1，其余900维=0。\n",
    "2. 调整分类算法的分类阈值，比如将LR中的默认阈值从0调整到0.9，降低recall提升精度。\n",
    "3. 各种算法的使用方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47206e",
   "metadata": {},
   "source": [
    "## 1、数据预处理\n",
    "\n",
    "### 样本格式\n",
    "最终得到的样本格式如下，第一列是label，第二列是一“|”分割的一些特征，可以理解为用户观看了哪部电影，喜欢哪本书，关注了哪个微博id等。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "736a3c63",
   "metadata": {},
   "source": [
    "label,features\n",
    "1,20018\n",
    "0,20006|20025\n",
    "1,1509|8713|2000341|9010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbe7e8",
   "metadata": {},
   "source": [
    "我们读取数据后，将数据做onehot。比如总共有10000个标签，如果设备带了其中1000个，则标签有10000列，其中1000列为1，其余为0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c74282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc7440",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f6b0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                           features\n",
      "0      1                                            2001841\n",
      "1      0                                    2000641|2002541\n",
      "2      1  1509|871305|2000341|901005|147409|132905|13560...\n",
      "3      1  1034005|20909|9505|1083505|69209|19109|10905|9...\n",
      "4      1  148009|4109|3809|169105|685006|62409|99805|200...\n"
     ]
    }
   ],
   "source": [
    "sample_dir = '/home/ljhn1829/jupyter_data/sklearn_onehot_threshold.csv'\n",
    "df_sample_all = pd.read_csv(sample_dir)\n",
    "print(df_sample_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5280ca6",
   "metadata": {},
   "source": [
    "### onehot\n",
    "\n",
    "除了本文的sklearn方式外，也可以使用pandas.get_dummies()。但数据量比较大，而且稀疏时，建议使用sklearn。\n",
    "\n",
    "见《sklearn系列之2：数据预处理》及https://stackoverflow.com/questions/63544536/convert-pd-get-dummies-result-to-df-str-get-dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844bd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1000005  100008  100009  10001  1000108  10002  1000208  10005  \\\n",
      "0      1        0       0       0      0        0      0        0      0   \n",
      "1      0        0       0       0      0        0      0        0      0   \n",
      "2      1        0       0       0      0        0      0        0      0   \n",
      "3      1        0       0       0      0        0      0        0      0   \n",
      "4      1        0       0       0      0        0      0        0      0   \n",
      "\n",
      "   10007  ...  998805  999008  99905  99908  99909  999505  999508  999708  \\\n",
      "0      0  ...       0       0      0      0      0       0       0       0   \n",
      "1      0  ...       0       0      0      0      0       0       0       0   \n",
      "2      0  ...       0       0      0      0      0       0       0       0   \n",
      "3      0  ...       0       0      0      0      0       0       0       0   \n",
      "4      0  ...       0       0      0      0      0       0       0       0   \n",
      "\n",
      "   999805  999808  \n",
      "0       0       0  \n",
      "1       0       0  \n",
      "2       0       0  \n",
      "3       0       0  \n",
      "4       0       0  \n",
      "\n",
      "[5 rows x 23720 columns]\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "onehot_output = pd.DataFrame.sparse.from_spmatrix(mlb.fit_transform(df_sample_all['features'].str.split('|')),\n",
    "                                           columns=mlb.classes_)\n",
    "df_sample_onehot_all = pd.DataFrame()\n",
    "df_sample_onehot_all['label'] = df_sample_all['label']\n",
    "df_sample_onehot_all= pd.concat([df_sample_onehot_all,onehot_output], axis=1)\n",
    "print(df_sample_onehot_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b878299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5493\n",
      "1    4506\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_sample_onehot_all['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea4f97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_sample_onehot_all['1000005'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ccba6",
   "metadata": {},
   "source": [
    "### 数据集拆分\n",
    "将数据集拆分为训练、测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b10b3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_set, test_set = train_test_split(df_sample_onehot_all, test_size=0.2, random_state=42)\n",
    "# test_set, train_set = df_sample_onehot_all[0:30], df_sample_onehot_all[30:100]\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffle_indices = np.random.permutation(len(data))\n",
    "    test_size = int(len(data) * test_ratio) \n",
    "    print(test_size)\n",
    "    training_idx, test_idx = shuffle_indices[test_size:], shuffle_indices[:test_size]\n",
    "    return data.iloc[training_idx], data.iloc[test_idx]\n",
    "\n",
    "train_set, test_set = split_train_test(df_sample_onehot_all, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e4ad4",
   "metadata": {},
   "source": [
    "看一下训练集和测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd47dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4384\n",
      "1    3616\n",
      "Name: label, dtype: int64\n",
      "0    1109\n",
      "1     890\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set['label'].value_counts())\n",
    "print(test_set['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a49498",
   "metadata": {},
   "source": [
    "将XY分开："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8c5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = train_set['label'], train_set.iloc[:, 1:]\n",
    "y_test, X_test = test_set['label'], test_set.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de8c06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  1000005  100008  100009  10001  1000108  10002  1000208  10005  \\\n",
      "45        1        0       0       0      0        0      0        0      0   \n",
      "9521      0        0       0       0      0        0      0        0      0   \n",
      "7718      0        0       0       0      0        0      0        0      0   \n",
      "7054      0        0       0       0      0        0      0        0      0   \n",
      "4605      1        0       0       0      0        0      0        0      0   \n",
      "\n",
      "      10007  ...  998805  999008  99905  99908  99909  999505  999508  999708  \\\n",
      "45        0  ...       0       0      0      0      0       0       0       0   \n",
      "9521      0  ...       0       0      0      0      0       0       0       0   \n",
      "7718      0  ...       0       0      0      0      0       0       0       0   \n",
      "7054      0  ...       0       0      0      0      0       0       0       0   \n",
      "4605      0  ...       0       0      0      0      0       0       0       0   \n",
      "\n",
      "      999805  999808  \n",
      "45         0       0  \n",
      "9521       0       0  \n",
      "7718       0       0  \n",
      "7054       0       0  \n",
      "4605       0       0  \n",
      "\n",
      "[5 rows x 23720 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89137466",
   "metadata": {},
   "source": [
    "看一下哪些属性和label最相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train_set.corr()\n",
    "corr_matrix['label'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba001b",
   "metadata": {},
   "source": [
    "## 2、模型训练\n",
    "我们使用各种模型训练上述数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df09dfb",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfba923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5722861430715358 0.5323741007194245 0.4884488448844885 0.5094664371772806 0.5653253398734368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "#clf = LogisticRegression(loss='log')\n",
    "clf = LogisticRegression(penalty='l2', C=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "#print(pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve,roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred)\n",
    "print(accuracy, precision, recall, f1, auc)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "# cross_val_score(clf, X_train, y_train, cv=3, scoring='recall')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73310364",
   "metadata": {},
   "source": [
    "### 阈值调整\n",
    "\n",
    "我们调整一下预测分类的阈值，LogisticRegression的预测范围是[-1,1]，阈值默认取0.0。\n",
    "\n",
    "下面我们先得到预测的具体数值，然后通过调整阈值的方式，调整其分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ff50da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21320269  0.25052858 -0.47845967 ...  0.83939436  0.36785\n",
      "  0.3116261 ]\n"
     ]
    }
   ],
   "source": [
    "y_score = clf.decision_function(X_test)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8579ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n",
      "0.5617808904452226 0.6222222222222222 0.0924092409240924 0.16091954022988506 0.5228101250492021\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.99\n",
    "y_predict_t = (y_score > threshold)\n",
    "print(y_predict_t)\n",
    "accuracy = accuracy_score(y_test, y_predict_t)\n",
    "precision = precision_score(y_test, y_predict_t)\n",
    "recall = recall_score(y_test, y_predict_t)\n",
    "f1 = f1_score(y_test, y_predict_t)\n",
    "auc = roc_auc_score(y_test, y_predict_t)\n",
    "print(accuracy, precision, recall, f1, auc)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e0c5e31",
   "metadata": {},
   "source": [
    "可以看到，提高阈值，可以降低recall，提升precision。\n",
    "也就是说，提高分类阈值，recall从0.49降到0.09，同时精度从0.53上升到0.62。\n",
    "阈值=0时，accuracy, precision, recall, f1, auc = 0.5722861430715358 0.5323741007194245 0.4884488448844885 0.5094664371772806 0.5653253398734368\n",
    "阈值=0.99时，accuracy, precision, recall, f1, auc = 0.5617808904452226 0.6222222222222222 0.0924092409240924 0.16091954022988506 0.5228101250492021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae94f6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "111c1cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5322661330665333 0.529358807440377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.42452043, 0.5646372 , 0.39366138])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve,roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "#precision_score(y_test, pred)\n",
    "#precision = precision_score(y_test, pred)\n",
    "#recall = recall_score(y_test, pred)\n",
    "#f1 = f1_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred)\n",
    "#print(accuracy, precision, recall, f1, uac)\n",
    "print(accuracy, auc)\n",
    "\n",
    "cross_val_score(clf, X_train, y_train, cv=3, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd3043",
   "metadata": {},
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9512ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5537768884442221 0.5478048263541951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve,roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "#precision_score(y_test, pred)\n",
    "#precision = precision_score(y_test, pred)\n",
    "#recall = recall_score(y_test, pred)\n",
    "#f1 = f1_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred)\n",
    "#print(accuracy, precision, recall, f1, uac)\n",
    "print(accuracy, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a7f60",
   "metadata": {},
   "source": [
    "## 深度学习Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2f17111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23719\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6861 - accuracy: 0.5537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f83b42c5a00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "columns_count = X_train.shape[1]\n",
    "print(columns_count)\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Flatten(input_shape=[columns_count,1])) #将输入的二维数组展开成一维向量\n",
    "# model.add(keras.layers.Dense(300,activation='relu'))\n",
    "# model.add(keras.layers.Dense(100,activation='relu'))\n",
    "# model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[columns_count,1]),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcdf1f",
   "metadata": {},
   "source": [
    "用Keras做文本二分类，总是遇到以下错误，我的类别是0或1，但是错误跟我说不能是1.\n",
    "\n",
    "参见：Received a label value of 1 which is outside the valid range of [0, 1) - Python, Keras loss function的问题。\n",
    "\n",
    "原来用的是sparse_categorical_crossentropy，改为binary_crossentropy问题解决。\n",
    "\n",
    "https://blog.csdn.net/The_Time_Runner/article/details/93889004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb741e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
